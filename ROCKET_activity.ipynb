{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kr7/ROCKET-DTW/blob/main/ROCKET_activity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqSAzuUhxf86"
      },
      "source": [
        "**Activity Recognition Based on Accelerometer Data with Enhanced ROCKET Algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1ziwkrzZXJN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy import random as rnd\n",
        "from scipy.io import arff\n",
        "from scipy.stats import ttest_rel\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.linear_model import RidgeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9q4gILbTZj0c",
        "outputId": "f1335bd1-e8da-44ae-ef3a-505b56632954"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-07 09:36:52--  https://timeseriesclassification.com/aeon-toolkit/Epilepsy.zip\n",
            "Resolving timeseriesclassification.com (timeseriesclassification.com)... 109.123.71.232\n",
            "Connecting to timeseriesclassification.com (timeseriesclassification.com)|109.123.71.232|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 809010 (790K) [application/zip]\n",
            "Saving to: ‘Epilepsy.zip’\n",
            "\n",
            "Epilepsy.zip        100%[===================>] 790.05K  1.61MB/s    in 0.5s    \n",
            "\n",
            "2024-02-07 09:36:53 (1.61 MB/s) - ‘Epilepsy.zip’ saved [809010/809010]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://timeseriesclassification.com/aeon-toolkit/Epilepsy.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8iufmeqZj56",
        "outputId": "512d3c58-ba7f-4c34-a321-f83f32d9528e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  Epilepsy.zip\n",
            "  inflating: Epilepsy.jpg            \n",
            "  inflating: Epilepsy.txt            \n",
            "  inflating: EpilepsyDimension1_TEST.arff  \n",
            "  inflating: EpilepsyDimension1_TRAIN.arff  \n",
            "  inflating: EpilepsyDimension2_TEST.arff  \n",
            "  inflating: EpilepsyDimension2_TRAIN.arff  \n",
            "  inflating: EpilepsyDimension3_TEST.arff  \n",
            "  inflating: EpilepsyDimension3_TRAIN.arff  \n",
            "  inflating: Epilepsy_TEST.arff      \n",
            "  inflating: Epilepsy_TRAIN.arff     \n",
            "  inflating: Epilepsy_TEST.ts        \n",
            "  inflating: Epilepsy_TRAIN.ts       \n"
          ]
        }
      ],
      "source": [
        "!unzip Epilepsy.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tiuEtx2A_IaH"
      },
      "outputs": [],
      "source": [
        "# In order to perform 10-fold cross-validation, we\n",
        "# will merge the provided train and test splits and\n",
        "# we will split the data durign the cross-validation\n",
        "\n",
        "NUM_CHANNELS = 3\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for filename in ['Epilepsy_TRAIN.arff', 'Epilepsy_TEST.arff' ]:\n",
        "  raw_data = arff.loadarff(filename)\n",
        "\n",
        "  nextInstance = True\n",
        "  i = 0\n",
        "\n",
        "  while nextInstance:\n",
        "    try:\n",
        "      dim1 = list(raw_data[0][i][0][0])\n",
        "      dim2 = list(raw_data[0][i][0][1])\n",
        "      dim3 = list(raw_data[0][i][0][2])\n",
        "      label = raw_data[0][i][1]\n",
        "\n",
        "      X.append([dim1,dim2,dim3])\n",
        "      if label == b'EPILEPSY':\n",
        "        label = 0\n",
        "      elif label == b'WALKING':\n",
        "        label = 1\n",
        "      elif label == b'RUNNING':\n",
        "        label = 2\n",
        "      elif label == b'SAWING':\n",
        "        label = 3\n",
        "      else:\n",
        "        print(f'Unexpected label: {label}')\n",
        "      y.append(label)\n",
        "\n",
        "      i = i+1\n",
        "    except:\n",
        "      nextInstance = False\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQ18Ds5YjR1d"
      },
      "outputs": [],
      "source": [
        "%load_ext cython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRw7dOrYkF6C"
      },
      "outputs": [],
      "source": [
        "%%cython\n",
        "\n",
        "cimport cython\n",
        "from libc.stdlib cimport malloc, free\n",
        "\n",
        "\n",
        "def dtw(ts1p, ts2p):\n",
        "    cdef int LEN_TS1\n",
        "    cdef int LEN_TS2\n",
        "    cdef int i\n",
        "    cdef int j\n",
        "    cdef float * ts1\n",
        "    cdef float * ts2\n",
        "    cdef float * dtw_matrix\n",
        "    cdef float d\n",
        "\n",
        "    LEN_TS1 = len(ts1p)\n",
        "    LEN_TS2 = len(ts2p)\n",
        "\n",
        "    ts1 = <float *> malloc(LEN_TS1*cython.sizeof(float))\n",
        "    ts2 = <float *> malloc(LEN_TS2*cython.sizeof(float))\n",
        "    dtw_matrix = <float *> malloc(LEN_TS1*LEN_TS2*cython.sizeof(float))\n",
        "      # this is a flattened DTW matrix dtw_matrix[i,j] -> dtw_matrix[i*LEN_TS2 + j]\n",
        "    if ts1 is NULL or ts2 is NULL:\n",
        "      raise MemoryError()\n",
        "    for i in xrange(LEN_TS1):\n",
        "      ts1[i] = ts1p[i]\n",
        "    for i in xrange(LEN_TS2):\n",
        "      ts2[i] = ts2p[i]\n",
        "\n",
        "    dtw_matrix[0] = abs(ts1[0]-ts2[0])\n",
        "\n",
        "    for i in range(1, LEN_TS1):\n",
        "      dtw_matrix[i*LEN_TS2] = dtw_matrix[(i-1)*LEN_TS2]+abs(ts1[i]-ts2[0])\n",
        "\n",
        "    for j in range(1, LEN_TS2):\n",
        "      dtw_matrix[j] = dtw_matrix[j-1]+abs(ts1[0]-ts2[j])\n",
        "\n",
        "    for i in range(1, LEN_TS1):\n",
        "      for j in range(1, LEN_TS2):\n",
        "        dtw_matrix[i*LEN_TS2+j] = min(dtw_matrix[(i-1)*LEN_TS2+j-1],\n",
        "                                      dtw_matrix[(i-1)*LEN_TS2+j],\n",
        "                                      dtw_matrix[i*LEN_TS2+j-1]) + abs(ts1[i]-ts2[j])\n",
        "\n",
        "    d=dtw_matrix[ LEN_TS1*LEN_TS2-1 ]\n",
        "\n",
        "    free(ts1)\n",
        "    free(ts2)\n",
        "    free(dtw_matrix)\n",
        "\n",
        "    return d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_Je9FlCbn5S"
      },
      "outputs": [],
      "source": [
        "def log2(x):\n",
        "  return np.log(x)/np.log(2)\n",
        "\n",
        "\n",
        "def get_random_convolution_params(seed, l_input):\n",
        "  rnd.seed(seed)\n",
        "  length = rnd.randint(0,2)*2+7\n",
        "  weights = rnd.normal(0,1, (NUM_CHANNELS, length) )\n",
        "  bias = float(rnd.uniform(-1, 1))\n",
        "  max_exp = np.floor(log2((l_input-1)/(length-1)))-1\n",
        "  dilation = int( 2**(rnd.uniform(0,max_exp)) )\n",
        "  padding = rnd.randint(0,1)\n",
        "  return (length, weights, bias, dilation, padding)\n",
        "\n",
        "\n",
        "def apply_convolution( time_series, convolution ):\n",
        "  length, weights, bias, dilation, padding = convolution\n",
        "  window_size = length*dilation\n",
        "  time_series = list(time_series)\n",
        "\n",
        "  if padding == 1:\n",
        "    zeros = [0]*(dilation*(length-1)/2)\n",
        "    for i in range(NUM_CHANNELS):\n",
        "      time_series[i] = zeros + time_series[i] + zeros\n",
        "\n",
        "  segments = np.array(\n",
        "      [ [ time_series[j][i:i+window_size:dilation] for j in range(NUM_CHANNELS) ]\n",
        "        for i in range(0, int(len(time_series[0])-window_size)) ])\n",
        "\n",
        "  conv = np.array([np.sum(s*weights) + bias for s in segments])\n",
        "  dtw_conv = np.array( [ np.sum([dtw(s[c], weights[c]) for c in range(len(s))]) for s in segments] )\n",
        "\n",
        "  return conv, dtw_conv\n",
        "\n",
        "\n",
        "def ppv(series):\n",
        "  return float(np.sum(series > 0) / np.size(series))\n",
        "\n",
        "\n",
        "def get_rocket_features(time_series_dataset, convolutional_filters):\n",
        "  dataset_features_max = [] # features with conventional convolution\n",
        "  dataset_features_ppv = [] # features with conventional convolution\n",
        "  dataset_features_dtw = [] # features with dynamic convolution\n",
        "  i = 0\n",
        "  for ts in time_series_dataset:\n",
        "    if i%10==0:\n",
        "      print(f\"{i:4}/{len(time_series_dataset)}\")\n",
        "    i = i+1\n",
        "\n",
        "    ts_features_max = []\n",
        "    ts_features_ppv = []\n",
        "    ts_features_dtw = []\n",
        "    for c in convolutional_filters:\n",
        "      convolved_ts, dtw_convolved_ts = apply_convolution(ts, c)\n",
        "      ts_features_max.append( float(max(convolved_ts)) )\n",
        "      ts_features_ppv.append( ppv(convolved_ts) )\n",
        "      ts_features_dtw.append( float(max(dtw_convolved_ts)) )\n",
        "       # PPV does not make sense for dTW!\n",
        "    dataset_features_max.append( ts_features_max )\n",
        "    dataset_features_ppv.append( ts_features_ppv )\n",
        "    dataset_features_dtw.append( ts_features_dtw )\n",
        "  return np.array(dataset_features_max), np.array(dataset_features_ppv), np.array(dataset_features_dtw)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convolutional filters are independent of the data (as their parameters are\n",
        "# sampled from random distributions), therefore the features based on\n",
        "# convolutional filters may be pre-calculated (so that they do not need to be\n",
        "# calculated in each round of the cross-validation which speeds up the\n",
        "# execution of the experiment)\n",
        "\n",
        "convolutional_filters = []\n",
        "length = len(X[0][0])\n",
        "for i in range(10000):\n",
        "  convolutional_filters.append(get_random_convolution_params(i, length))\n",
        "\n",
        "features_max, features_ppv, features_dtw = get_rocket_features(X, convolutional_filters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l45wX3uBKaRX",
        "outputId": "68c6093f-562e-4a5c-dec9-173233862fcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   0/275\n",
            "  10/275\n",
            "  20/275\n",
            "  30/275\n",
            "  40/275\n",
            "  50/275\n",
            "  60/275\n",
            "  70/275\n",
            "  80/275\n",
            "  90/275\n",
            " 100/275\n",
            " 110/275\n",
            " 120/275\n",
            " 130/275\n",
            " 140/275\n",
            " 150/275\n",
            " 160/275\n",
            " 170/275\n",
            " 180/275\n",
            " 190/275\n",
            " 200/275\n",
            " 210/275\n",
            " 220/275\n",
            " 230/275\n",
            " 240/275\n",
            " 250/275\n",
            " 260/275\n",
            " 270/275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pI9qXl_IcVca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a74eb0c7-d40a-4435-8a52-516a8b3d5089"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD:  0\n",
            "FOLD:  1\n",
            "FOLD:  2\n",
            "FOLD:  3\n",
            "FOLD:  4\n",
            "FOLD:  5\n",
            "FOLD:  6\n",
            "FOLD:  7\n",
            "FOLD:  8\n",
            "FOLD:  9\n",
            "FOLD: 10\n",
            "FOLD: 11\n",
            "FOLD: 12\n",
            "FOLD: 13\n",
            "FOLD: 14\n",
            "FOLD: 15\n",
            "FOLD: 16\n",
            "FOLD: 17\n",
            "FOLD: 18\n",
            "FOLD: 19\n",
            "FOLD: 20\n",
            "FOLD: 21\n",
            "FOLD: 22\n",
            "FOLD: 23\n",
            "FOLD: 24\n",
            "FOLD: 25\n",
            "FOLD: 26\n",
            "FOLD: 27\n",
            "FOLD: 28\n",
            "FOLD: 29\n",
            "FOLD: 30\n",
            "FOLD: 31\n",
            "FOLD: 32\n",
            "FOLD: 33\n",
            "FOLD: 34\n",
            "FOLD: 35\n",
            "FOLD: 36\n",
            "FOLD: 37\n",
            "FOLD: 38\n",
            "FOLD: 39\n",
            "FOLD: 40\n",
            "FOLD: 41\n",
            "FOLD: 42\n",
            "FOLD: 43\n",
            "FOLD: 44\n",
            "FOLD: 45\n",
            "FOLD: 46\n",
            "FOLD: 47\n",
            "FOLD: 48\n",
            "FOLD: 49\n",
            "FOLD: 50\n",
            "FOLD: 51\n",
            "FOLD: 52\n",
            "FOLD: 53\n",
            "FOLD: 54\n",
            "FOLD: 55\n",
            "FOLD: 56\n",
            "FOLD: 57\n",
            "FOLD: 58\n",
            "FOLD: 59\n",
            "FOLD: 60\n",
            "FOLD: 61\n",
            "FOLD: 62\n",
            "FOLD: 63\n",
            "FOLD: 64\n",
            "FOLD: 65\n",
            "FOLD: 66\n",
            "FOLD: 67\n",
            "FOLD: 68\n",
            "FOLD: 69\n",
            "FOLD: 70\n",
            "FOLD: 71\n",
            "FOLD: 72\n",
            "FOLD: 73\n",
            "FOLD: 74\n",
            "FOLD: 75\n",
            "FOLD: 76\n",
            "FOLD: 77\n",
            "FOLD: 78\n",
            "FOLD: 79\n",
            "FOLD: 80\n",
            "FOLD: 81\n",
            "FOLD: 82\n",
            "FOLD: 83\n",
            "FOLD: 84\n",
            "FOLD: 85\n",
            "FOLD: 86\n",
            "FOLD: 87\n",
            "FOLD: 88\n",
            "FOLD: 89\n",
            "FOLD: 90\n",
            "FOLD: 91\n",
            "FOLD: 92\n",
            "FOLD: 93\n",
            "FOLD: 94\n",
            "FOLD: 95\n",
            "FOLD: 96\n",
            "FOLD: 97\n",
            "FOLD: 98\n",
            "FOLD: 99\n"
          ]
        }
      ],
      "source": [
        "# 10-times 10-fold cross-validation\n",
        "\n",
        "all_err_rocket = np.zeros( (100) )\n",
        "all_err_ppv = np.zeros( (100) )\n",
        "all_err_max = np.zeros( (100) )\n",
        "all_err_dtw = np.zeros( (100) )\n",
        "all_err_combined = np.zeros( (100) )\n",
        "fold = 0\n",
        "\n",
        "for seed in range(10):\n",
        "  kf = StratifiedKFold(n_splits=10, random_state=seed+42, shuffle=True)\n",
        "  for train_index, test_index in kf.split(X, y):\n",
        "    print(f\"FOLD: {fold:2}\")\n",
        "    features_train_max = features_max[train_index]\n",
        "    features_train_ppv = features_ppv[train_index]\n",
        "    features_train_dtw = features_dtw[train_index]\n",
        "    features_test_max = features_max[test_index]\n",
        "    features_test_ppv = features_ppv[test_index]\n",
        "    features_test_dtw = features_dtw[test_index]\n",
        "\n",
        "    y_train = y[train_index]\n",
        "    y_test  = y[test_index]\n",
        "\n",
        "    cls = RidgeClassifier()\n",
        "    cls.fit( np.hstack((features_train_max, features_train_ppv)), y_train)\n",
        "    pred = cls.predict( np.hstack((features_test_max, features_test_ppv)) )\n",
        "    all_err_rocket[fold] = np.mean(pred != y_test)\n",
        "\n",
        "    cls = RidgeClassifier()\n",
        "    cls.fit( features_train_ppv, y_train )\n",
        "    pred = cls.predict( features_test_ppv )\n",
        "    all_err_ppv[fold] = np.mean(pred != y_test)\n",
        "\n",
        "    cls = RidgeClassifier()\n",
        "    cls.fit( features_train_max, y_train )\n",
        "    pred = cls.predict( features_test_max )\n",
        "    all_err_max[fold] = np.mean(pred != y_test)\n",
        "\n",
        "    cls = RidgeClassifier()\n",
        "    cls.fit( features_train_dtw, y_train )\n",
        "    pred = cls.predict( features_test_dtw )\n",
        "    all_err_dtw[fold] = np.mean(pred != y_test)\n",
        "\n",
        "    cls = RidgeClassifier()\n",
        "    cls.fit( np.hstack((features_train_max, features_train_ppv, features_train_dtw)), y_train)\n",
        "    pred = cls.predict( np.hstack((features_test_max, features_test_ppv, features_test_dtw)) )\n",
        "    all_err_combined[fold] = np.mean(pred != y_test)\n",
        "\n",
        "    fold = fold + 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print( \"Method                    Classification error  p-values\")\n",
        "print(f\"ROCKET                    \"+\n",
        "      f\"{np.mean(all_err_rocket):6.4f} +/- {np.std(all_err_rocket):6.4f}  \")\n",
        "print(f\"ROCKET-PPV                \"+\n",
        "      f\"{np.mean(all_err_ppv):6.4f} +/- {np.std(all_err_ppv):6.4f}  \")\n",
        "print(f\"ROCKET-MAX                \"+\n",
        "      f\"{np.mean(all_err_max):6.4f} +/- {np.std(all_err_max):6.4f}  \")\n",
        "print(f\"ROCKET-DTW (our approach) \"+\n",
        "      f\"{np.mean(all_err_dtw):6.4f} +/- {np.std(all_err_dtw):6.4f}     \"+\n",
        "      f\"{ttest_rel(all_err_rocket, all_err_dtw)[1]:5.3f}  \"+\n",
        "      f\"{ttest_rel(all_err_ppv, all_err_dtw)[1]:5.3f}  \"+\n",
        "      f\"{ttest_rel(all_err_max, all_err_dtw)[1]:5.3f}  \")\n",
        "print(f\"ROCKET-Combined           \"+\n",
        "      f\"{np.mean(all_err_combined):6.4f} +/- {np.std(all_err_combined):6.4f}     \"+\n",
        "      f\"{ttest_rel(all_err_rocket, all_err_combined)[1]:5.3f}  \"+\n",
        "      f\"{ttest_rel(all_err_ppv, all_err_combined)[1]:5.3f}  \"+\n",
        "      f\"{ttest_rel(all_err_max, all_err_combined)[1]:5.3f}  \"+\n",
        "      f\"{ttest_rel(all_err_dtw, all_err_combined)[1]:5.3f}  \")"
      ],
      "metadata": {
        "id": "O9LuSRVDh1fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e70987a7-4330-43a8-a334-2a2b99a29896"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Method                    Classification error  p-values\n",
            "ROCKET                    0.0174 +/- 0.0220  \n",
            "ROCKET-PPV                0.0154 +/- 0.0254  \n",
            "ROCKET-MAX                0.0261 +/- 0.0318  \n",
            "ROCKET-DTW (our approach) 0.0018 +/- 0.0079     0.000  0.000  0.000  \n",
            "ROCKET-Combined           0.0047 +/- 0.0121     0.000  0.000  0.000  0.004  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tn3qcmL3rGqq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPhmfp4Yhfw6yiW1dbm0xRt",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}